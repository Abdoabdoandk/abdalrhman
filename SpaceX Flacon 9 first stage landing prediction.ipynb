{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting data by webscraping\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "static_url = \"https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922\"\n",
    "url = requests.get(static_url).text\n",
    "soup = BeautifulSoup(url,'html5lib')\n",
    "def date_time(table_cells):\n",
    "    return [data_time.strip() for data_time in list(table_cells.strings)][0:2]\n",
    "\n",
    "def get_mass(table_cells):\n",
    "    mass=unicodedata.normalize(\"NFKD\", table_cells.text).strip()\n",
    "    if mass:\n",
    "        mass.find(\"kg\")\n",
    "        new_mass=mass[0:mass.find(\"kg\")+2]\n",
    "    else:\n",
    "        new_mass=0\n",
    "    return new_mass \n",
    "  \n",
    "html_tables = soup.find_all('table')\n",
    "first_launch_table = html_tables[2]\n",
    "x = first_launch_table.find('tr').find_all('th')\n",
    "column_names = []\n",
    "for y in x :\n",
    "    name = ' '.join(y.stripped_strings)\n",
    "    if name :\n",
    "        column_names.append(name)\n",
    "column_names[2].strip('[b]')\n",
    "column_names[4].strip(' [c]')\n",
    "launch_dict= dict.fromkeys(column_names)\n",
    "del launch_dict['Date and time ( UTC )']\n",
    "launch_dict['Flight No.'] = []\n",
    "launch_dict['Launch site'] = []\n",
    "launch_dict['Payload [c]'] = []\n",
    "launch_dict['Payload mass'] = []\n",
    "launch_dict['Orbit'] = []\n",
    "launch_dict['Customer'] = []\n",
    "launch_dict['Launch outcome'] = []\n",
    "launch_dict['Version, Booster [b]']=[]\n",
    "launch_dict['Booster landing']=[]\n",
    "launch_dict['Date']=[]\n",
    "launch_dict['Time']=[]\n",
    "extracted_row = 0\n",
    "for table_number,table in enumerate(soup.find_all('table',\"wikitable plainrowheaders collapsible\")):\n",
    "    for rows in table.find_all(\"tr\"):\n",
    "        if rows.th:\n",
    "            if rows.th.string:\n",
    "                flight_number=rows.th.string.strip()\n",
    "                flag=flight_number.isdigit()\n",
    "        else:\n",
    "            flag=False\n",
    "        row=rows.find_all('td')\n",
    "        if flag:\n",
    "            extracted_row += 1\n",
    "            launch_dict['Flight No.'].append(flight_number)\n",
    "            \n",
    "            # Date value\n",
    "            fulldate = list(row[0].strings)\n",
    "            date = fulldate[0].strip(',')\n",
    "            launch_dict['Date'].append(date)\n",
    "            \n",
    "            # Time value\n",
    "            time = fulldate[1].strip()\n",
    "            launch_dict['Time'].append(time)\n",
    "              \n",
    "            # Booster version\n",
    "            z = list(row[1].strings)[0:3:2]\n",
    "            bv = ' '.join(z) \n",
    "\n",
    "            launch_dict['Version, Booster [b]'].append(bv) \n",
    "            \n",
    "            # Launch Site\n",
    "            launch_site1 = list(row[2].strings)[0:3:2]\n",
    "            launch_site = ' '.join(launch_site1) \n",
    "            launch_dict['Launch site'].append(launch_site)\n",
    "            \n",
    "            \n",
    "            # Payload\n",
    "            payload = row[3].a.string\n",
    "            launch_dict['Payload [c]'].append(payload)\n",
    "            \n",
    "            # Payload Mass\n",
    "            payload_mass = get_mass(row[4])\n",
    "            launch_dict['Payload mass'].append(payload_mass)\n",
    "            \n",
    "            # Orbit\n",
    "            orbit = row[5].text.strip()\n",
    "            launch_dict['Orbit'].append(orbit)\n",
    "            \n",
    "            # Customer\n",
    "            customer= row[6].text.strip()\n",
    "            launch_dict['Customer'].append(customer) \n",
    "        \n",
    "            \n",
    "            \n",
    "            # Launch outcome\n",
    "            launch_outcome = list(row[7].strings)[0].strip()\n",
    "            launch_dict['Launch outcome'].append(launch_outcome)\n",
    "            \n",
    "            # Booster landing\n",
    "            booster_landing = list(row[8].strings)[0].strip()\n",
    "            launch_dict['Booster landing'].append(booster_landing)\n",
    "\n",
    "df= pd.DataFrame({ key:pd.Series(value) for key, value in launch_dict.items() })\n",
    "df.rename(columns={'Version, Booster [b]':'Version Booster'},inplace=True)\n",
    "df.rename(columns={'Payload [c]':'Payload'},inplace=True)\n",
    "df.to_csv('spacex_web_scrabed.csv',index=False)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting data by APIs\n",
    "# that is an additional way of collecting data with web scraping\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "def getBoosterVersion(data):\n",
    "    for x in data['rocket']:\n",
    "       if x:\n",
    "        response = requests.get(\"https://api.spacexdata.com/v4/rockets/\"+str(x)).json()\n",
    "        BoosterVersion.append(response['name'])\n",
    "def getLaunchSite(data):\n",
    "    for x in data['launchpad']:\n",
    "       if x:\n",
    "         response = requests.get(\"https://api.spacexdata.com/v4/launchpads/\"+str(x)).json()\n",
    "         Longitude.append(response['longitude'])\n",
    "         Latitude.append(response['latitude'])\n",
    "         LaunchSite.append(response['name'])\n",
    "def getPayloadData(data):\n",
    "    for load in data['payloads']:\n",
    "       if load:\n",
    "        response = requests.get(\"https://api.spacexdata.com/v4/payloads/\"+load).json()\n",
    "        PayloadMass.append(response['mass_kg'])\n",
    "        Orbit.append(response['orbit'])\n",
    "def getCoreData(data):\n",
    "    for core in data['cores']:\n",
    "            if core['core'] != None:\n",
    "                response = requests.get(\"https://api.spacexdata.com/v4/cores/\"+core['core']).json()\n",
    "                Block.append(response['block'])\n",
    "                ReusedCount.append(response['reuse_count'])\n",
    "                Serial.append(response['serial'])\n",
    "            else:\n",
    "                Block.append(None)\n",
    "                ReusedCount.append(None)\n",
    "                Serial.append(None)\n",
    "            Outcome.append(str(core['landing_success'])+' '+str(core['landing_type']))\n",
    "            Flights.append(core['flight'])\n",
    "            GridFins.append(core['gridfins'])\n",
    "            Reused.append(core['reused'])\n",
    "            Legs.append(core['legs'])\n",
    "            LandingPad.append(core['landpad'])\n",
    "static_json_url='https://api.spacexdata.com/v4/launches/past'\n",
    "response = requests.get(static_json_url).json()\n",
    "data = pd.json_normalize(response)\n",
    "data = data[['rocket', 'payloads', 'launchpad', 'cores', 'flight_number', 'date_utc']]\n",
    "\n",
    "data = data[data['cores'].map(len)==1]\n",
    "data = data[data['payloads'].map(len)==1]\n",
    "\n",
    "data['cores'] = data['cores'].map(lambda x : x[0])\n",
    "data['payloads'] = data['payloads'].map(lambda x : x[0])\n",
    "\n",
    "data['date'] = pd.to_datetime(data['date_utc']).dt.date\n",
    "\n",
    "data = data[data['date'] <= datetime.date(2020, 11, 13)]\n",
    "BoosterVersion = []\n",
    "PayloadMass = []\n",
    "Orbit = []\n",
    "LaunchSite = []\n",
    "Outcome = []\n",
    "Flights = []\n",
    "GridFins = []\n",
    "Reused = []\n",
    "Legs = []\n",
    "LandingPad = []\n",
    "Block = []\n",
    "ReusedCount = []\n",
    "Serial = []\n",
    "Longitude = []\n",
    "Latitude = []\n",
    "getBoosterVersion(data)\n",
    "getLaunchSite(data)\n",
    "getPayloadData(data)\n",
    "getCoreData(data)\n",
    "launch_dict = {'FlightNumber': list(data['flight_number']),\n",
    "'Date': list(data['date']),\n",
    "'BoosterVersion':BoosterVersion,\n",
    "'PayloadMass':PayloadMass,\n",
    "'Orbit':Orbit,\n",
    "'LaunchSite':LaunchSite,\n",
    "'Outcome':Outcome,\n",
    "'Flights':Flights,\n",
    "'GridFins':GridFins,\n",
    "'Reused':Reused,\n",
    "'Legs':Legs,\n",
    "'LandingPad':LandingPad,\n",
    "'Block':Block,\n",
    "'ReusedCount':ReusedCount,\n",
    "'Serial':Serial,\n",
    "'Longitude': Longitude,\n",
    "'Latitude': Latitude}\n",
    "df = pd.DataFrame(launch_dict)\n",
    "data_falcon9 = df[df['BoosterVersion'] == 'Falcon 9']\n",
    "data_falcon9.loc[:,'FlightNumber'] = range(1,91,1)\n",
    "data_falcon9['PayloadMass'].replace(np.nan,data_falcon9['PayloadMass'].mean(),inplace=True)\n",
    "data_falcon9.head()\n",
    "data_falcon9.to_csv('dataset_part_1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv('dataset_part_1.csv')\n",
    "outcome_landing = df['Outcome'].value_counts()\n",
    "bad_outcomes = list(outcome_landing.keys()[[1,3,5,6,7]])\n",
    "df['class'] = np.where(df['Outcome'].isin(bad_outcomes), 0, 1)\n",
    "#df['class'].mean()\n",
    "#df.groupby('Orbit')['Outcome'].value_counts().to_frame()\n",
    "#df['Outcome'].value_counts()\n",
    "df.head()\n",
    "df.to_csv('dataset_part_2.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA with SQL\n",
    "import pandas as pd\n",
    "import csv, sqlite3\n",
    "%load_ext sql\n",
    "%sql sqlite:///my_data1.db\n",
    "con = sqlite3.connect(\"my_data1.db\")\n",
    "cur = con.cursor()\n",
    "df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/data/Spacex.csv\")\n",
    "df.to_sql(\"SPACEXTBL\", con, if_exists='replace', index=False,method=\"multi\")\n",
    "%sql create table SPACEXTABLE as select * from SPACEXTBL where Date is not null\n",
    "%sql select * from SPACEXTABLE limit 5\n",
    "%%sql\n",
    "select distinct(Launch_Site) from SPACEXTABLE \n",
    "select * from SPACEXTABLE where Launch_Site like 'CCA%' limit 5\n",
    "select Customer, sum(PAYLOAD_MASS__KG_) as total_payload_mass from SPACEXTABLE where Customer = 'NASA (CRS)'\n",
    "select Booster_Version, avg(PAYLOAD_MASS__KG_) as avg_payload_mass from SPACEXTABLE where Booster_Version = 'F9 v1.1'\n",
    "select min(Date),Landing_Outcome from SPACEXTABLE where Landing_Outcome like 'Success%'\n",
    "select Booster_Version,PAYLOAD_MASS__KG_,Landing_Outcome  from SPACEXTABLE where Landing_Outcome = 'Success (drone ship)'  AND PAYLOAD_MASS__KG_ Between 4000 and 6000\n",
    "select Mission_Outcome, count(Mission_Outcome) from SPACEXTABLE group by Mission_Outcome\n",
    "select Booster_version,PAYLOAD_MASS__KG_ from SPACEXTABLE where PAYLOAD_MASS__KG_ = (select MAX(PAYLOAD_MASS__KG_) from SPACEXTABLE)\n",
    "select Date, substr(Date,6,2) as month ,Landing_Outcome, Booster_Version , Launch_Site from SPACEXTABLE where Landing_Outcome like 'Failure (drone ship)' AND substr(Date,1,4)='2015'\n",
    "select Landing_Outcome, count(Landing_Outcome) as count from SPACEXTABLE where Date BETWEEN '2010-06-04' AND '2017-03-20' GROUP BY Landing_Outcome ORDER BY Count DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SpaceX prediction \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import train_test_split,GridSearchCV \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import log_loss,jaccard_score,f1_score\n",
    "pd.set_option('display.max_columns', None)\n",
    "df=pd.read_csv(\"dataset_part_2 (1).csv\")\n",
    "df = df[['PayloadMass','Orbit','LaunchSite','Serial','Flights','GridFins','Reused','Legs','Block','ReusedCount','Class']]\n",
    "df[['GridFins','Reused','Legs','Block']] = df[['GridFins','Reused','Legs','Block']].astype(int)\n",
    "df = pd.get_dummies(df).astype(int)\n",
    "x = df.drop(columns='Class').values\n",
    "y = df['Class'].values \n",
    "x = preprocessing.StandardScaler().fit(x).transform(x.astype(int))\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=4)\n",
    "\n",
    "df.head()\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "param_grid = {'criterion': ['gini', 'entropy'],\n",
    "     'splitter': ['best', 'random'],\n",
    "     'max_features': ['auto', 'sqrt'],\n",
    "     'min_samples_leaf': [1, 2, 4],\n",
    "     'min_samples_split': [2, 5, 10]}\n",
    "model = DecisionTreeClassifier()\n",
    "grid_search_decision_tree = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search_decision_tree.fit(x_train,y_train)\n",
    "print(\"Best Parameters: \", grid_search_decision_tree.best_params_)\n",
    "print(\"Best Score: \", grid_search_decision_tree.best_score_)\n",
    "best_model = grid_search_decision_tree.best_estimator_\n",
    "print(best_model)\n",
    "yhat=grid_search_decision_tree.predict(x_test)\n",
    "yhat[0:10],y_test[0:10]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "param_grid = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "              'p': [1,2]}\n",
    "model = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(x_train,y_train)\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "best_model = grid_search.best_estimator_\n",
    "print(best_model)\n",
    "yhat=grid_search.predict(x_test)\n",
    "yhat[0:10],y_test[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [0.1, 0.01, 0.001], 'kernel': ['rbf', 'linear']}\n",
    "model = SVC()\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(x_train,y_train)\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "best_model = grid_search.best_estimator_\n",
    "print(best_model)\n",
    "yhat=grid_search.predict(x_test)\n",
    "yhat[0:10],y_test[0:10]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "param_grid = {'C': [0.01,0.1, 1, 10, 100], 'solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']}\n",
    "model = LogisticRegression()\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(x_train,y_train)\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "best_model = grid_search.best_estimator_\n",
    "print(best_model)\n",
    "yhat=grid_search.predict(x_test)\n",
    "yhat[0:10],y_test[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assuming new data to precict its class\n",
    "pd.set_option('display.max_columns', None)\n",
    "df=pd.read_csv(\"dataset_part_2 (1).csv\")\n",
    "df1 = df.drop(columns='Class')\n",
    "#last row of df1 is the row that hold the new data we want to have prediction on it\n",
    "df1.loc[len(df1)] = {'FlightNumber':91,\t'Date':2013-12-1 ,\t'BoosterVersion':'Falcon 9',\t'PayloadMass':986,\t'Orbit':'LEO',\t'LaunchSite':'CCAFS SLC 40','Outcome':'None None',\t'Flights':2,\t'GridFins':1,\t'Reused':0,\t'Legs':1,\t'LandingPad':'NaN',\t'Block':2,\t'ReusedCount':5,\t'Serial':'B1060',\t'Longitude':-80.577366,\t'Latitude':28.561857}\n",
    "df1 = df1[['PayloadMass','Orbit','LaunchSite','Serial','Flights','GridFins','Reused','Legs','Block','ReusedCount']]\n",
    "df1['Block'] = df1['Block'].astype(int)\n",
    "df1 = pd.get_dummies(df1).astype(int).values\n",
    "df1 = preprocessing.StandardScaler().fit(df1).transform(df1.astype(int))\n",
    "k = df1[90]\n",
    "k = k.reshape(1, -1)\n",
    "#Decision Tree\n",
    "yhat=grid_search_decision_tree.predict(k)\n",
    "yhat\n",
    "# it will have successfull landing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
